# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MtGN2qzxbiguWM-dOrUbKRGOWkMVGJ9V
"""

#Download dataset dari github
!wget --no-check-certificate \
  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip\
  -O /tmp/rockpaperscissors.zip

# Mengimport Library yang digunakan
import numpy as np
import tensorflow as tf
import zipfile
import os
import shutil
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

#ekstrak dataset
local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

# Menyiapkan folder untuk data gambar Gunting, Batu, Kertas
folder_path = '/tmp/rockpaperscissors'
folders = {
    'scissors': os.path.join(folder_path, 'scissors'),
    'rock': os.path.join(folder_path, 'rock'),
    'paper': os.path.join(folder_path, 'paper')
}

# Menampilkan jumlah total gambar tiap label
for label, folder in folders.items():
    num_images = len(os.listdir(folder))
    print(f"Jumlah total gambar {label}: {num_images}")

#menyiapkan ImageDataGen and path
path = "/tmp/rockpaperscissors/rps-cv-images/"
training_datagen = ImageDataGenerator(
      rescale = 1./255,
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      validation_split=0.4          #training data 60% : 40% validasi
      )

#Pelabelan data
train_generator = training_datagen.flow_from_directory (
    path ,
    target_size = (150 , 150) ,
    shuffle = True,
    subset = "training" ,
    class_mode='categorical'

)

validation_generator = training_datagen.flow_from_directory(
	path ,
	target_size=(150,150),
	class_mode='categorical',
  shuffle=True,
  subset='validation'
)

#Membuat Model CNN
model = tf.keras.models.Sequential([

    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5),

    tf.keras.layers.Dense(128, activation='relu'),

    tf.keras.layers.Dense(512, activation='relu'),

    tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

#compile model
model.compile(loss = 'categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

#Training CNN model menggunakan callback()

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy')>0.95):
      print("\nTraining Berhenti, >95%!")
      self.model.stop_training = True

callbacks = myCallback()

history=model.fit(
    train_generator,
    steps_per_epoch=16,  #steps_per_epoch = total_images / batch_size
    epochs=75,
    validation_data=validation_generator,
    validation_steps=4,
    verbose=2,
    callbacks=[callbacks]
    )

# Mengambil metrik dari riwayat pelatihan model
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc) + 1)  # Menghitung jumlah epochs dari riwayat

# Plotting grafik untuk akurasi
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(epochs, acc, 'r', label='Akurasi Training')
plt.plot(epochs, val_acc, 'b', label='Akurasi Validasi')
plt.title('Akurasi Training dan Validasi')
plt.xlabel('Epochs')
plt.ylabel('Akurasi')
plt.legend()

# Plotting grafik untuk loss
plt.subplot(1, 2, 2)
plt.plot(epochs, loss, 'r', label='Loss Training')
plt.plot(epochs, val_loss, 'b', label='Loss Validasi')
plt.title('Loss Training dan Validasi')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Commented out IPython magic to ensure Python compatibility.

from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():

  path = fn
  img = image.load_img(path, target_size =(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)

  print(fn)
  if classes[0][0]==1:
    print('Ini adalah Kertas')
  elif classes[0][1]==1:
    print('Ini adalah Batu')
  elif classes[0][2]==1:
    print('Ini adalah Gunting')
  else:
    print('ndak tau')

#M.Hanif Fajar Anggara
#hanifanggara1@gmail.com

